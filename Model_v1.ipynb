{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRanker\n",
    "from scipy.stats import kendalltau\n",
    "from sklearn.metrics import ndcg_score\n",
    "from scipy.stats import spearmanr\n",
    "from fuzzywuzzy import process\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('RCBKKR.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Calculate the number of null values in each column\n",
    "null_values = df.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of null values in each column\n",
    "null_percentage = (null_values / len(df)) * 100\n",
    "\n",
    "# Combine the null values and their percentages into a DataFrame\n",
    "null_summary = pd.DataFrame({'Null Values': null_values, 'Percentage': null_percentage})\n",
    "\n",
    "print(null_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Select only the integer and float type columns\n",
    "int_float_columns = df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = int_float_columns.corr()\n",
    "\n",
    "# Create a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# List of categorical columns to test\n",
    "categorical_columns = ['team', 'batter', 'bowler', 'city', 'venue', 'Batter_role', 'retained', 'stage']\n",
    "\n",
    "# Dictionary to store the results\n",
    "chi2_results = {}\n",
    "\n",
    "# Perform chi-square test for each categorical column\n",
    "for col in categorical_columns:\n",
    "    contingency_table = pd.crosstab(df[col], df['Total Points'])\n",
    "    chi2, p, dof, ex = chi2_contingency(contingency_table)\n",
    "    chi2_results[col] = p\n",
    "\n",
    "# Convert the results to a DataFrame for better visualization\n",
    "chi2_results_df = pd.DataFrame(list(chi2_results.items()), columns=['Feature', 'p-value'])\n",
    "\n",
    "print(chi2_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop & Scale Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['matches', 'match_id', 'event_name', 'match_type', 'match_number','matches_played_till_date', 'retained',\n",
    "                   'matches_played_till_date_2', 'match_date', 'batter_id', 'Year', 'known_as', 'season_info', 'match_number_info']\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling not needed for RF & XGBoost it will help to avoid post prediction reverse scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "sorted_unique_teams = sorted(df['team'].unique().tolist())\n",
    "print(sorted_unique_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the replacements\n",
    "replacements = {\n",
    "    'Deccan Chargers': 'Sunrisers Hyderabad',\n",
    "    'Delhi Daredevils': 'Delhi Capitals',\n",
    "    'Gujarat Lions': 'Gujarat Titans',\n",
    "    'Kings XI Punjab': 'Punjab Kings',\n",
    "    'Rising Pune Supergiant': 'Rising Pune Supergiants',\n",
    "    'Royal Challengers Bangalore': 'Royal Challengers Bengaluru'\n",
    "}\n",
    "\n",
    "# Replace the team names in the 'team' column\n",
    "df['team'] = df['team'].replace(replacements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Season/Year conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df['season'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df['Year_Since'] = 2025 - df['season']\n",
    "\n",
    "df['Year_Since'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "unique_pairs = df[['Year_Since', 'season']].drop_duplicates()\n",
    "print(unique_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['season'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Validation Set (2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df['Year_Since'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2024 = df[df['Year_Since'] == 1]\n",
    "\n",
    "df = df[df['Year_Since'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df_2024.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df['Year_Since'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove records of seasons from 2008 till 2014\n",
    "df = df[~df['Year_Since'].isin(range(11, 17))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns to encode\n",
    "categorical_columns = ['batter', 'bowler', 'team', 'city', 'venue', 'Batter_role', 'stage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "# Initialize the target encoder\n",
    "target_encoder = ce.TargetEncoder(cols=categorical_columns)\n",
    "\n",
    "# Fit the encoder on the training data and transform it\n",
    "df_encoded = target_encoder.fit_transform(df[categorical_columns], df['Total Points'])\n",
    "\n",
    "# Transform the validation data using the same encoder\n",
    "df_2024_encoded = target_encoder.transform(df_2024[categorical_columns])\n",
    "\n",
    "# Store original categories before replacing them\n",
    "original_categories = {col: df[col].copy() for col in categorical_columns}\n",
    "\n",
    "# Replace the original categorical columns with the encoded values\n",
    "df[categorical_columns] = df_encoded\n",
    "df_2024[categorical_columns] = df_2024_encoded\n",
    "\n",
    "# Create a reverse mapping dictionary\n",
    "coding_map = {}\n",
    "df_unique = df[categorical_columns].copy()  # Copy only categorical columns\n",
    "\n",
    "# Transform only unique values while keeping the full DataFrame structure\n",
    "df_transformed = target_encoder.transform(df_unique)\n",
    "\n",
    "for col in categorical_columns:\n",
    "    unique_categories = original_categories[col].unique()\n",
    "    transformed_values = df_transformed[col].values  # Get transformed values\n",
    "    coding_map[col] = dict(zip(transformed_values, unique_categories))  # Create mapping\n",
    "\n",
    "print(\"Encoding completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output variables\n",
    "X = df.drop(columns=['Total Points'])\n",
    "y = df['Total Points']\n",
    "X_2024 = df_2024.drop(columns=['Total Points'])\n",
    "y_2024 = df_2024['Total Points']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Create the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test predictions & store train predictions for meta model\n",
    "\n",
    "rf_train_preds = rf.predict(X_train)\n",
    "rf_test_preds = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, rf_test_preds)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, rf_test_preds)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, rf_test_preds)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]\n",
    "p = X_test.shape[1]\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Adjusted R-squared: {adjusted_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Make predictions on the 2024 data using the Random Forest model\n",
    "rf_2024_preds = rf.predict(X_2024)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE) for the 2024 predictions\n",
    "mae_2024 = mean_absolute_error(y_2024, rf_2024_preds)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for the 2024 predictions\n",
    "mse_2024 = mean_squared_error(y_2024, rf_2024_preds)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for the 2024 predictions\n",
    "rmse_2024 = np.sqrt(mse_2024)\n",
    "\n",
    "# Calculate R-squared for the 2024 predictions\n",
    "r2_2024 = r2_score(y_2024, rf_2024_preds)\n",
    "\n",
    "# Calculate Adjusted R-squared for the 2024 predictions\n",
    "n_2024 = X_2024.shape[0]\n",
    "p_2024 = X_2024.shape[1]\n",
    "adjusted_r2_2024 = 1 - (1 - r2_2024) * (n_2024 - 1) / (n_2024 - p_2024 - 1)\n",
    "\n",
    "print(f'Mean Absolute Error (MAE) for 2024: {mae_2024}')\n",
    "print(f'Mean Squared Error (MSE) for 2024: {mse_2024}')\n",
    "print(f'Root Mean Squared Error (RMSE) for 2024: {rmse_2024}')\n",
    "print(f'R-squared for 2024: {r2_2024}')\n",
    "print(f'Adjusted R-squared for 2024: {adjusted_r2_2024}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2024['rf_2024_preds'] = rf_2024_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for col in categorical_columns:\n",
    "    df_2024[col] = df_2024[col].map(coding_map[col])\n",
    "\n",
    "print(\"Reverse encoding completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df_2024.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Create the XGBoost model\n",
    "xgb = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test predictions & store train predictions for meta model\n",
    "\n",
    "xgb_train_preds = xgb.predict(X_train)\n",
    "xgb_test_preds = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, xgb_test_preds)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, xgb_test_preds)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, xgb_test_preds)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]\n",
    "p = X_test.shape[1]\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Adjusted R-squared: {adjusted_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank = df.copy()\n",
    "df_rank['rank'] = df_rank.groupby(['Year_Since', 'bowler'])['Total Points'].rank(ascending=False, method='first')\n",
    "df_rank['rank'] = df_rank['rank'].astype(int)\n",
    "df_rank = df_rank.drop(columns=['Total Points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df_rank['rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output variables\n",
    "X_rank = df_rank.drop(columns=['rank'])\n",
    "y_rank = df_rank['rank']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_rank, X_test_rank, y_train_rank, y_test_rank = train_test_split(X_rank, y_rank, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Ensures no values exceed the expected range\n",
    "#y_train_rank = y_train_rank.clip(0, 30)\n",
    "\n",
    "ranker = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"gbdt\",\n",
    "    n_estimators=500\n",
    ")\n",
    "\n",
    "\n",
    "# Number of matches in training data\n",
    "num_matches = len(X_train_rank) // 242  \n",
    "\n",
    "# Create a list where each match has 242 records\n",
    "group_sizes = np.full(num_matches, 242, dtype=int)\n",
    "\n",
    "# Adjust the last group to ensure total sum matches X_train\n",
    "difference = len(X_train_rank) - sum(group_sizes)\n",
    "if difference != 0:\n",
    "    group_sizes[-1] += difference  # Absorb the difference in the last group\n",
    "\n",
    "print(\"New Sum of group_sizes:\", sum(group_sizes))\n",
    "print(\"Expected dataset size:\", len(X_train_rank))\n",
    "\n",
    "# Fit the model with the corrected group parameter\n",
    "ranker.fit(X_train_rank, y_train_rank, group=group_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test predictions & store train predictions for meta model\n",
    "\n",
    "lgb_train_preds = ranker.predict(X_train_rank)\n",
    "lgb_test_preds = ranker.predict(X_test_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "tau, _ = kendalltau(y_test_rank, lgb_test_preds)\n",
    "print(\"Kendall’s Tau:\", tau)\n",
    "\n",
    "\n",
    "rho, _ = spearmanr(y_test_rank, lgb_test_preds)\n",
    "print(\"Spearman’s Rank Correlation:\", rho)\n",
    "\n",
    "\n",
    "\n",
    "ndcg = ndcg_score([y_test_rank], [lgb_test_preds])\n",
    "print(\"NDCG Score:\", ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank_2024 = df_2024.copy()\n",
    "df_rank_2024['rank'] = df_rank_2024.groupby(['Year_Since', 'bowler'])['Total Points'].rank(ascending=False, method='first') \n",
    "df_rank_2024['rank'] = df_rank_2024['rank'].astype(int) \n",
    "df_rank_2024 = df_rank_2024.drop(columns=['Total Points'])\n",
    "\n",
    "X_rank_2024 = df_rank_2024.drop(columns=['rank'])\n",
    "y_rank_2024 = df_rank_2024['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rank_2024 = X_rank_2024.drop(columns=['rf_2024_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on the 2024 data using the LightGBM model\n",
    "lgb_2024_preds = ranker.predict(X_rank_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "tau, _ = kendalltau(y_rank_2024, lgb_2024_preds)\n",
    "print(\"Kendall’s Tau:\", tau)\n",
    "\n",
    "\n",
    "rho, _ = spearmanr(y_rank_2024, lgb_2024_preds)\n",
    "print(\"Spearman’s Rank Correlation:\", rho)\n",
    "\n",
    "\n",
    "\n",
    "ndcg = ndcg_score([y_rank_2024], [lgb_2024_preds])\n",
    "print(\"NDCG Score:\", ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meta-features for training data\n",
    "meta_train = np.column_stack((rf_train_preds, xgb_train_preds, lgb_train_preds))\n",
    "meta_train_df = pd.DataFrame(meta_train, columns=['rf_pred', 'xgb_pred', 'lgb_pred'])\n",
    "\n",
    "# Create meta-features for test data\n",
    "meta_test = np.column_stack((rf_test_preds, xgb_test_preds, lgb_test_preds))\n",
    "meta_test_df = pd.DataFrame(meta_test, columns=['rf_pred', 'xgb_pred', 'lgb_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "meta_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Create the XGBoost model\n",
    "meta_model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "meta_model.fit(meta_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_preds = meta_model.predict(meta_train_df)\n",
    "final_test_preds = meta_model.predict(meta_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, final_test_preds)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, final_test_preds)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, final_test_preds)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]\n",
    "p = X_test.shape[1]\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Adjusted R-squared: {adjusted_r2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
